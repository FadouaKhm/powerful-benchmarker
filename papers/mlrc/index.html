



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.dev0, mkdocs-material-4.6.0">
    
    
      
        <title>A Metric Learning Reality Check - Powerful Benchmarker</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application.1b62728e.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/application-palette.a8b3c06d.css">
      
      
        
        
        <meta name="theme-color" content="">
      
    
    
      <script src="../../assets/javascripts/modernizr.268332fc.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../assets/fonts/material-icons.css">
    
    
    
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="black" data-md-color-accent="blue">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#a-metric-learning-reality-check" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../.." title="Powerful Benchmarker" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Powerful Benchmarker
            </span>
            <span class="md-header-nav__topic">
              
                A Metric Learning Reality Check
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/KevinMusgrave/powerful-benchmarker/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    KevinMusgrave/powerful-benchmarker
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../.." title="Powerful Benchmarker" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Powerful Benchmarker
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/KevinMusgrave/powerful-benchmarker/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    KevinMusgrave/powerful-benchmarker
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../cl_syntax/" title="Command Line Syntax" class="md-nav__link">
      Command Line Syntax
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../yaml_syntax/" title="Yaml Syntax" class="md-nav__link">
      Yaml Syntax
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../hyperparams/" title="Hyperparameter Optimization" class="md-nav__link">
      Hyperparameter Optimization
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../custom/" title="Adding Custom Modules" class="md-nav__link">
      Adding Custom Modules
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      Default Config File Guide
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        Default Config File Guide
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../configs/config_dataset/" title="config_dataset" class="md-nav__link">
      config_dataset
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../configs/config_eval/" title="config_eval" class="md-nav__link">
      config_eval
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../configs/config_factories/" title="config_factories" class="md-nav__link">
      config_factories
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../configs/config_general/" title="config_general" class="md-nav__link">
      config_general
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../configs/config_loss_and_miners/" title="config_loss_and_miners" class="md-nav__link">
      config_loss_and_miners
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../configs/config_models/" title="config_models" class="md-nav__link">
      config_models
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../configs/config_optimizers/" title="config_optimizers" class="md-nav__link">
      config_optimizers
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../configs/config_transforms/" title="config_transforms" class="md-nav__link">
      config_transforms
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7" type="checkbox" id="nav-7">
    
    <label class="md-nav__link" for="nav-7">
      Code Documentation
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-7">
        Code Documentation
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/aggregators/" title="Aggregators" class="md-nav__link">
      Aggregators
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/api_parsers/" title="API Parsers" class="md-nav__link">
      API Parsers
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/architectures/" title="Architectures" class="md-nav__link">
      Architectures
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/datasets/" title="Datasets" class="md-nav__link">
      Datasets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/ensembles/" title="Ensembles" class="md-nav__link">
      Ensembles
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/factories/" title="Factories" class="md-nav__link">
      Factories
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/runners/" title="Runners" class="md-nav__link">
      Runners
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/split_managers/" title="Split Managers" class="md-nav__link">
      Split Managers
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/utils/" title="Utils" class="md-nav__link">
      Utils
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-8" type="checkbox" id="nav-8" checked>
    
    <label class="md-nav__link" for="nav-8">
      Papers
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-8">
        Papers
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        A Metric Learning Reality Check
      </label>
    
    <a href="./" title="A Metric Learning Reality Check" class="md-nav__link md-nav__link--active">
      A Metric Learning Reality Check
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#optimization-plots" class="md-nav__link">
    Optimization plots
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimal-hyperparameters" class="md-nav__link">
    Optimal hyperparameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples-of-unfair-comparisons-in-metric-learning-papers" class="md-nav__link">
    Examples of unfair comparisons in metric learning papers
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#papers-that-use-a-better-architecture-than-their-competitors-but-dont-disclose-it" class="md-nav__link">
    Papers that use a better architecture than their competitors, but don’t disclose it.
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-use-a-higher-dimensionality-than-their-competitors-but-dont-disclose-it" class="md-nav__link">
    Papers that use a higher dimensionality than their competitors, but don’t disclose it.
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-claim-to-do-a-simple-256-resize-and-227-random-crop-but-actually-use-the-more-advanced-randomresizedcrop-method" class="md-nav__link">
    Papers that claim to do a simple 256 resize and 227 random crop, but actually use the more advanced RandomResizedCrop method:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-omit-details" class="md-nav__link">
    Papers that omit details:
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples-to-back-up-other-claims-in-section-21" class="md-nav__link">
    Examples to back up other claims in section 2.1
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#most-papers-claim-to-apply-the-following-transformations-resize-the-image-to-256-x-256-randomly-crop-to-227-x-227-and-do-a-horizontal-flip-with-50-chance-the-following-papers-support-this-claim" class="md-nav__link">
    “Most papers claim to apply the following transformations: resize the image to 256 x 256, randomly crop to 227 x 227, and do a horizontal flip with 50% chance”. The following papers support this claim:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-categorized-by-the-optimizer-they-use" class="md-nav__link">
    Papers categorized by the optimizer they use:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-do-not-use-confidence-intervals" class="md-nav__link">
    Papers that do not use confidence intervals:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-do-not-use-a-validation-set" class="md-nav__link">
    Papers that do not use a validation set:
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#frequently-asked-questions" class="md-nav__link">
    Frequently Asked Questions
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#do-you-have-slides-that-accompany-the-paper" class="md-nav__link">
    Do you have slides that accompany the paper?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#isnt-it-unfair-to-fix-the-model-optimizer-learning-rate-and-embedding-size" class="md-nav__link">
    Isn't it unfair to fix the model, optimizer, learning rate, and embedding size?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-was-the-batch-size-set-to-32-for-most-of-the-results" class="md-nav__link">
    Why was the batch size set to 32 for most of the results?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-werent-more-hard-mining-methods-evaluated" class="md-nav__link">
    Why weren't more hard-mining methods evaluated?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-the-contrastive-loss-why-is-the-optimal-positive-margin-a-negative-value" class="md-nav__link">
    For the contrastive loss, why is the optimal positive margin a negative value?
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reproducing-results" class="md-nav__link">
    Reproducing results
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#download-the-experiment-folder" class="md-nav__link">
    Download the experiment folder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#command-line-scripts" class="md-nav__link">
    Command line scripts
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-evaluation-on-the-test-set" class="md-nav__link">
    Run evaluation on the test set
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#optimization-plots" class="md-nav__link">
    Optimization plots
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimal-hyperparameters" class="md-nav__link">
    Optimal hyperparameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples-of-unfair-comparisons-in-metric-learning-papers" class="md-nav__link">
    Examples of unfair comparisons in metric learning papers
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#papers-that-use-a-better-architecture-than-their-competitors-but-dont-disclose-it" class="md-nav__link">
    Papers that use a better architecture than their competitors, but don’t disclose it.
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-use-a-higher-dimensionality-than-their-competitors-but-dont-disclose-it" class="md-nav__link">
    Papers that use a higher dimensionality than their competitors, but don’t disclose it.
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-claim-to-do-a-simple-256-resize-and-227-random-crop-but-actually-use-the-more-advanced-randomresizedcrop-method" class="md-nav__link">
    Papers that claim to do a simple 256 resize and 227 random crop, but actually use the more advanced RandomResizedCrop method:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-omit-details" class="md-nav__link">
    Papers that omit details:
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples-to-back-up-other-claims-in-section-21" class="md-nav__link">
    Examples to back up other claims in section 2.1
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#most-papers-claim-to-apply-the-following-transformations-resize-the-image-to-256-x-256-randomly-crop-to-227-x-227-and-do-a-horizontal-flip-with-50-chance-the-following-papers-support-this-claim" class="md-nav__link">
    “Most papers claim to apply the following transformations: resize the image to 256 x 256, randomly crop to 227 x 227, and do a horizontal flip with 50% chance”. The following papers support this claim:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-categorized-by-the-optimizer-they-use" class="md-nav__link">
    Papers categorized by the optimizer they use:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-do-not-use-confidence-intervals" class="md-nav__link">
    Papers that do not use confidence intervals:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-do-not-use-a-validation-set" class="md-nav__link">
    Papers that do not use a validation set:
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#frequently-asked-questions" class="md-nav__link">
    Frequently Asked Questions
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#do-you-have-slides-that-accompany-the-paper" class="md-nav__link">
    Do you have slides that accompany the paper?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#isnt-it-unfair-to-fix-the-model-optimizer-learning-rate-and-embedding-size" class="md-nav__link">
    Isn't it unfair to fix the model, optimizer, learning rate, and embedding size?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-was-the-batch-size-set-to-32-for-most-of-the-results" class="md-nav__link">
    Why was the batch size set to 32 for most of the results?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-werent-more-hard-mining-methods-evaluated" class="md-nav__link">
    Why weren't more hard-mining methods evaluated?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-the-contrastive-loss-why-is-the-optimal-positive-margin-a-negative-value" class="md-nav__link">
    For the contrastive loss, why is the optimal positive margin a negative value?
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reproducing-results" class="md-nav__link">
    Reproducing results
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#download-the-experiment-folder" class="md-nav__link">
    Download the experiment folder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#command-line-scripts" class="md-nav__link">
    Command line scripts
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-evaluation-on-the-test-set" class="md-nav__link">
    Run evaluation on the test set
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/KevinMusgrave/powerful-benchmarker/edit/master/docs/papers/mlrc.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="a-metric-learning-reality-check">A Metric Learning Reality Check<a class="headerlink" href="#a-metric-learning-reality-check" title="Permanent link">&para;</a></h1>
<p>This page contains additional information for the <a href="https://arxiv.org/abs/2003.08505">ECCV 2020 paper</a> by Musgrave et al.</p>
<h2 id="optimization-plots">Optimization plots<a class="headerlink" href="#optimization-plots" title="Permanent link">&para;</a></h2>
<p>Click on the links below to view the bayesian optimization plots. </p>
<p>These are also available in the <a href="https://docs.google.com/spreadsheets/d/1brUBishNxmld-KLDAJewIc43A4EVZk3gY6yKe8OIKbY/">benchmark spreadsheet</a>.</p>
<table>
<thead>
<tr>
<th>CUB200</th>
<th>Cars196</th>
<th>SOP</th>
<th>CUB200 with Batch 256</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="../mlrc_plots/cub_contrastive.html" target="_blank">Contrastive</a></td>
<td><a href="../mlrc_plots/cars_contrastive.html" target="_blank">Contrastive</a></td>
<td><a href="../mlrc_plots/sop_contrastive.html" target="_blank">Contrastive</a></td>
<td><a href="../mlrc_plots/cub_contrastive_large_batch.html" target="_blank">Contrastive</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_triplet.html" target="_blank">Triplet</a></td>
<td><a href="../mlrc_plots/cars_triplet.html" target="_blank">Triplet</a></td>
<td><a href="../mlrc_plots/sop_triplet.html" target="_blank">Triplet</a></td>
<td><a href="../mlrc_plots/cub_triplet_large_batch.html" target="_blank">Triplet</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_ntxent.html" target="_blank">NTXent</a></td>
<td><a href="../mlrc_plots/cars_ntxent.html" target="_blank">NTXent</a></td>
<td><a href="../mlrc_plots/sop_ntxent.html" target="_blank">NTXent</a></td>
<td><a href="../mlrc_plots/cub_ntxent_large_batch.html" target="_blank">NTXent</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_proxy_nca.html" target="_blank">ProxyNCA</a></td>
<td><a href="../mlrc_plots/cars_proxy_nca.html" target="_blank">ProxyNCA</a></td>
<td><a href="../mlrc_plots/sop_proxy_nca.html" target="_blank">ProxyNCA</a></td>
<td><a href="../mlrc_plots/cub_proxy_nca_large_batch.html" target="_blank">ProxyNCA</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_margin_no_weight_decay.html" target="_blank">Margin</a></td>
<td><a href="../mlrc_plots/cars_margin_no_weight_decay.html" target="_blank">Margin</a></td>
<td><a href="../mlrc_plots/sop_margin_no_weight_decay.html" target="_blank">Margin</a></td>
<td><a href="../mlrc_plots/cub_margin_large_batch_no_weight_decay.html" target="_blank">Margin</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_margin_param_per_class_no_weight_decay.html" target="_blank">Margin / class</a></td>
<td><a href="../mlrc_plots/cars_margin_param_per_class_no_weight_decay.html" target="_blank">Margin / class</a></td>
<td><a href="../mlrc_plots/sop_margin_param_per_class_no_weight_decay.html" target="_blank">Margin / class</a></td>
<td><a href="../mlrc_plots/cub_margin_param_per_class_large_batch_no_weight_decay.html" target="_blank">Margin / class</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_normalized_softmax.html" target="_blank">Normalized Softmax</a></td>
<td><a href="../mlrc_plots/cars_normalized_softmax.html" target="_blank">Normalized Softmax</a></td>
<td><a href="../mlrc_plots/sop_normalized_softmax.html" target="_blank">Normalized Softmax</a></td>
<td><a href="../mlrc_plots/cub_normalized_softmax_large_batch.html" target="_blank">Normalized Softmax</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_cosface.html" target="_blank">CosFace</a></td>
<td><a href="../mlrc_plots/cars_cosface.html" target="_blank">CosFace</a></td>
<td><a href="../mlrc_plots/sop_cosface.html" target="_blank">CosFace</a></td>
<td><a href="../mlrc_plots/cub_cosface_large_batch.html" target="_blank">CosFace</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_arcface.html" target="_blank">ArcFace</a></td>
<td><a href="../mlrc_plots/cars_arcface.html" target="_blank">ArcFace</a></td>
<td><a href="../mlrc_plots/sop_arcface.html" target="_blank">ArcFace</a></td>
<td><a href="../mlrc_plots/cub_arcface_large_batch.html" target="_blank">ArcFace</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_fast_ap.png" target="_blank">FastAP</a></td>
<td><a href="../mlrc_plots/cars_fast_ap.png" target="_blank">FastAP</a></td>
<td><a href="../mlrc_plots/sop_fast_ap.png" target="_blank">FastAP</a></td>
<td><a href="../mlrc_plots/cub_fastap_large_batch.html" target="_blank">FastAP</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_snr_contrastive.html" target="_blank">SNR Contrastive</a></td>
<td><a href="../mlrc_plots/cars_snr_contrastive.html" target="_blank">SNR Contrastive</a></td>
<td><a href="../mlrc_plots/sop_snr_contrastive.html" target="_blank">SNR Contrastive</a></td>
<td><a href="../mlrc_plots/cub_snr_contrastive_large_batch.html" target="_blank">SNR Contrastive</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_multi_similarity.html" target="_blank">Multi Similarity</a></td>
<td><a href="../mlrc_plots/cars_multi_similarity.html" target="_blank">Multi Similarity</a></td>
<td><a href="../mlrc_plots/sop_multi_similarity.html" target="_blank">Multi Similarity</a></td>
<td><a href="../mlrc_plots/cub_multi_similarity_large_batch.html" target="_blank">Multi Similarity</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_multi_similarity_with_ms_miner.html" target="_blank">Multi Similarity + Miner</a></td>
<td><a href="../mlrc_plots/cars_multi_similarity_with_ms_miner.html" target="_blank">Multi Similarity + Miner</a></td>
<td><a href="../mlrc_plots/sop_multi_similarity_with_ms_miner.html" target="_blank">Multi Similarity + Miner</a></td>
<td><a href="../mlrc_plots/cub_multi_similarity_with_ms_miner_large_batch_wider_range.html" target="_blank">Multi Similarity + Miner</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_soft_triple.html" target="_blank">SoftTriple</a></td>
<td><a href="../mlrc_plots/cars_soft_triple.html" target="_blank">SoftTriple</a></td>
<td><a href="../mlrc_plots/sop_soft_triple.html" target="_blank">SoftTriple</a></td>
<td><a href="../mlrc_plots/cub_soft_triple_large_batch_wider_range.html" target="_blank">SoftTriple</a></td>
</tr>
</tbody>
</table>
<h2 id="optimal-hyperparameters">Optimal hyperparameters<a class="headerlink" href="#optimal-hyperparameters" title="Permanent link">&para;</a></h2>
<p>The values below are also available in the <a href="https://docs.google.com/spreadsheets/d/1brUBishNxmld-KLDAJewIc43A4EVZk3gY6yKe8OIKbY/">benchmark spreadsheet</a>.</p>
<table>
<thead>
<tr>
<th>Loss function</th>
<th>CUB200</th>
<th>Cars196</th>
<th>SOP</th>
<th>CUB200 with Batch 256</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Contrastive</strong><br/>pos_margin<br/>neg_margin</td>
<td><br/>-0.2000<br/>0.3841</td>
<td><br/>0.2652<br/>0.5409</td>
<td><br/>0.2850<br/>0.5130</td>
<td><br/>0.2227<br/>0.7694</td>
</tr>
<tr>
<td><strong>Triplet</strong><br/>margin</td>
<td><br/>0.0961</td>
<td><br/>0.1190</td>
<td><br/>0.0451</td>
<td><br/>0.1368</td>
</tr>
<tr>
<td><strong>NTXent</strong><br/>temperature</td>
<td><br/>0.0091</td>
<td><br/>0.0219</td>
<td><br/>0.0002</td>
<td><br/>0.0415</td>
</tr>
<tr>
<td><strong>ProxyNCA</strong><br/>proxy lr<br/>softmax_scale</td>
<td><br/>6.04e-3<br/>13.98</td>
<td><br/>4.43e-3<br/>7.97</td>
<td><br/>5.28e-4<br/>10.73</td>
<td><br/>2.16e-1<br/>10.03</td>
</tr>
<tr>
<td><strong>Margin</strong><br/>beta lr<br/>margin<br/>init beta</td>
<td><br/>1.31e-3<br/>0.0878<br/>0.7838<br/></td>
<td><br/>1.11e-4<br/>0.0781<br/>1.3164<br/></td>
<td><br/>1.82e-3<br/>0.0915<br/>1.1072</td>
<td><br/>1.00e-6<br/>0.0674<br/>0.9762</td>
</tr>
<tr>
<td><strong>Margin / class</strong><br/>beta lr<br/>margin<br/>init beta</td>
<td><br/>2.65e-4<br/>0.0779<br/>0.9796</td>
<td><br/>4.76e-05<br/>0.0776<br/>0.9598</td>
<td><br/>7.10e-05<br/>0.0518<br/>0.8424</td>
<td><br/>1.32e-2<br/>-0.0204<br/>0.1097</td>
</tr>
<tr>
<td><strong>Normalized Softmax</strong><br/>weights lr<br/>temperature</td>
<td><br/>4.46e-3<br/>0.1087</td>
<td><br/>1.10e-2<br/>0.0886</td>
<td><br/>5.46e-4<br/>0.0630</td>
<td><br/>7.20e-2<br/>0.0707</td>
</tr>
<tr>
<td><strong>CosFace</strong><br/>weights lr<br/>margin<br/>scale<br/></td>
<td><br/>2.53e-3<br/>0.6182<br/>100.0</td>
<td><br/>7.41e-3<br/>0.4324<br/>161.5</td>
<td><br/>2.16e-3<br/>0.3364<br/>100.0</td>
<td><br/>3.99e-3<br/>0.4144<br/>88.23</td>
</tr>
<tr>
<td><strong>ArcFace</strong><br/>weights lr<br/>margin<br/>scale<br/></td>
<td><br/>5.13e-3<br/>23.22<br/>100.0</td>
<td><br/>7.39e-06<br/>20.52<br/>49.50</td>
<td><br/>2.01e-3<br/>18.63<br/>220.3</td>
<td><br/>3.95e-2<br/>23.14<br/>78.86</td>
</tr>
<tr>
<td><strong>FastAP</strong><br/>num_bins</td>
<td><br/>17</td>
<td><br/>27</td>
<td><br/>16</td>
<td><br/>86</td>
</tr>
<tr>
<td><strong>SNR Contrastive</strong><br/>pos_margin<br/>neg_margin<br/>regularizer_weight</td>
<td><br/>0.3264<br/>0.8446<br/>0.1382</td>
<td><br/>0.1670<br/>0.9337<br/>0</td>
<td><br/>0.3759<br/>1.0831<br/>0</td>
<td><br/>0.1182<br/>0.6822<br/>0.4744</td>
</tr>
<tr>
<td><strong>Multi Similarity</strong><br/>alpha<br/>beta<br/>base</td>
<td><br/>0.01<br/>50.60<br/>0.56</td>
<td><br/>14.35<br/>75.83<br/>0.66</td>
<td><br/>8.49<br/>57.38<br/>0.41</td>
<td><br/>0.01<br/>46.85<br/>0.82</td>
</tr>
<tr>
<td><strong>Multi Similarity + Miner</strong><br/>alpha<br/>beta<br/>base<br/>epsilon</td>
<td><br/>17.97<br/>75.66<br/>0.77<br/>0.39</td>
<td><br/>7.49<br/>47.99<br/>0.63<br/>0.72</td>
<td><br/>15.94<br/>156.61<br/>0.72<br/>0.34</td>
<td><br/>11.63<br/>55.20<br/>0.85<br/>0.42</td>
</tr>
<tr>
<td><strong>SoftTriple</strong><br/>weights lr<br/>la<br/>gamma<br/>reg_weight<br/>margin</td>
<td><br/>5.37e-05<br/>78.02<br/>58.95<br/>0.3754<br/>0.4307</td>
<td><br/>1.40e-4<br/>17.69<br/>19.18<br/>0.0669<br/>0.3588</td>
<td><br/>8.68e-05<br/>100.00<br/>47.90<br/>N/A<br/>0.3145</td>
<td><br/>1.06e-4<br/>72.12<br/>51.07<br/>0.4430<br/>0.6959</td>
</tr>
</tbody>
</table>
<h2 id="examples-of-unfair-comparisons-in-metric-learning-papers">Examples of unfair comparisons in metric learning papers<a class="headerlink" href="#examples-of-unfair-comparisons-in-metric-learning-papers" title="Permanent link">&para;</a></h2>
<h4 id="papers-that-use-a-better-architecture-than-their-competitors-but-dont-disclose-it">Papers that use a better architecture than their competitors, but don’t disclose it.<a class="headerlink" href="#papers-that-use-a-better-architecture-than-their-competitors-but-dont-disclose-it" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Sampling Matters in Deep Embedding Learning (ICCV 2017)</p>
<ul>
<li>Uses ResNet50, but all competitors use GoogleNet</li>
</ul>
</li>
<li>
<p>Deep Metric Learning with Hierarchical Triplet Loss (ECCV 2018)</p>
<ul>
<li>Uses BN-Inception, but all competitors use GoogleNet</li>
</ul>
</li>
<li>
<p>Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning (CVPR 2019)</p>
<ul>
<li>Uses BN-Inception. Claims better performance than ensemble methods, but the ensemble methods use GoogleNet.</li>
</ul>
</li>
<li>
<p>Deep Metric Learning to Rank (CVPR 2019)</p>
<ul>
<li>Uses ResNet50. In their SOP table, only 1 out of 11 competitor methods use ResNet50. All others use BN-Inception or GoogleNet. Claims better performance than ensemble methods, but the ensemble methods use GoogleNet. </li>
</ul>
</li>
<li>
<p>Divide and Conquer the Embedding Space for Metric Learning (CVPR 2019)</p>
<ul>
<li>Uses ResNet50. In their Cars196 and SOP tables, only 1 out of 15 competitor methods use ResNet50. The rest use GoogleNet or BN-Inception. The same is true for their CUB200 results, but in that table, they re-implement two of the competitors to use ResNet50.</li>
</ul>
</li>
<li>
<p>SoftTriple Loss: Deep Metric Learning Without Triplet Sampling (ICCV 2019)</p>
<ul>
<li>Uses BN-Inception. Compares with N-pairs and HDC, but doesn’t mention that these use GoogleNet. They only mention the competitors’ architectures when the competitors use an equal or superior network. Specifically, they mention that the Margin loss uses ResNet50,and HTL uses BN-Inception.</li>
</ul>
</li>
<li>
<p>Deep Metric Learning with Tuplet Margin Loss (ICCV 2019)</p>
<ul>
<li>Uses ResNet50. In their SOP table, only 1 out of 10 competitors use ResNet50, and in their CUB200 and Cars196 tables, only 1 out of 8 competitors use ResNet50. The rest use GoogleNet or BN-Inception. They also claim better performance than ensemble methods, but the ensemble methods use GoogleNet.</li>
</ul>
</li>
</ul>
<h4 id="papers-that-use-a-higher-dimensionality-than-their-competitors-but-dont-disclose-it">Papers that use a higher dimensionality than their competitors, but don’t disclose it.<a class="headerlink" href="#papers-that-use-a-higher-dimensionality-than-their-competitors-but-dont-disclose-it" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Sampling Matters in Deep Embedding Learning (ICCV 2017)</p>
<ul>
<li>Uses size 128. CUB200 table: 4 out of 7 use size 64. Cars196: 4 out of 5 use size 64. SOP: 4 out of 7 use size 64.</li>
</ul>
</li>
<li>
<p>Deep Metric Learning with Hierarchical Triplet Loss (ECCV 2018)</p>
<ul>
<li>Uses size 512. The top two non-ensemble competitor results use size 384 and 64.</li>
</ul>
</li>
<li>
<p>Ranked List Loss for Deep Metric Learning (CVPR 2019)</p>
<ul>
<li>Uses size 512 or 1536. For all 3 datasets, 5 out of the 6 competitor results use size 64.</li>
</ul>
</li>
<li>
<p>Deep Metric Learning with Tuplet Margin Loss (ICCV 2019)</p>
<ul>
<li>Uses size 512. The only competing method that uses the same architecture, uses size 128.</li>
</ul>
</li>
</ul>
<h4 id="papers-that-claim-to-do-a-simple-256-resize-and-227-random-crop-but-actually-use-the-more-advanced-randomresizedcrop-method">Papers that claim to do a simple 256 resize and 227 random crop, but actually use the more advanced RandomResizedCrop method:<a class="headerlink" href="#papers-that-claim-to-do-a-simple-256-resize-and-227-random-crop-but-actually-use-the-more-advanced-randomresizedcrop-method" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning (CVPR 2019)</p>
<ul>
<li><a href="https://github.com/MalongTech/research-ms-loss/blob/master/ret_benchmark/data/transforms/build.py#L17" target="_blank">Link to line in code</a></li>
</ul>
</li>
<li>
<p>Divide and Conquer the Embedding Space for Metric Learning (CVPR 2019)</p>
<ul>
<li><a href="https://github.com/CompVis/metric-learning-divide-and-conquer/blob/master/lib/data/set/transform.py#L51" target="_blank">Link to line in code</a></li>
</ul>
</li>
<li>
<p>MIC: Mining Interclass Characteristics for Improved Metric Learning (ICCV 2019)</p>
<ul>
<li><a href="https://github.com/Confusezius/ICCV2019_MIC/blob/master/datasets.py#L324" target="_blank">Link to line in code</a></li>
</ul>
</li>
<li>
<p>SoftTriple Loss: Deep Metric Learning Without Triplet Sampling (ICCV 2019)</p>
<ul>
<li><a href="https://github.com/idstcv/SoftTriple/blob/master/train.py#L99" target="_blank">Link to line in code</a></li>
</ul>
</li>
<li>
<p>Proxy Anchor Loss for Deep Metric Learning (CVPR 2020)</p>
<ul>
<li><a href="https://github.com/tjddus9597/Proxy-Anchor-CVPR2020/blob/master/code/dataset/utils.py#L76" target="_blank">Link to line in code</a></li>
</ul>
</li>
</ul>
<h4 id="papers-that-omit-details">Papers that omit details:<a class="headerlink" href="#papers-that-omit-details" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning (CVPR 2019)</p>
<ul>
<li><a href="https://github.com/MalongTech/research-ms-loss/blob/master/ret_benchmark/utils/freeze_bn.py" target="_blank">Freezes batchnorm parameters in their code</a>, but this is not mentioned in the paper.</li>
</ul>
</li>
<li>
<p>Proxy Anchor Loss for Deep Metric Learning (CVPR 2020)</p>
<ul>
<li>Uses the <a href="https://github.com/tjddus9597/Proxy-Anchor-CVPR2020/issues/1" target="_blank">sum of Global Average Pooling (GAP) and Global Max Pooling (GMP)</a>. Competitor papers use just GAP. This is not mentioned in the paper. </li>
</ul>
</li>
</ul>
<h2 id="examples-to-back-up-other-claims-in-section-21">Examples to back up other claims in section 2.1<a class="headerlink" href="#examples-to-back-up-other-claims-in-section-21" title="Permanent link">&para;</a></h2>
<h4 id="most-papers-claim-to-apply-the-following-transformations-resize-the-image-to-256-x-256-randomly-crop-to-227-x-227-and-do-a-horizontal-flip-with-50-chance-the-following-papers-support-this-claim">“Most papers claim to apply the following transformations: resize the image to 256 x 256, randomly crop to 227 x 227, and do a horizontal flip with 50% chance”. The following papers support this claim:<a class="headerlink" href="#most-papers-claim-to-apply-the-following-transformations-resize-the-image-to-256-x-256-randomly-crop-to-227-x-227-and-do-a-horizontal-flip-with-50-chance-the-following-papers-support-this-claim" title="Permanent link">&para;</a></h4>
<ul>
<li>Deep Metric Learning via Lifted Structured Feature Embedding (CVPR 2016)</li>
<li>Deep Spectral Clustering Learning (ICML 2017)</li>
<li>Deep Metric Learning via Facility Location (CVPR 2017)</li>
<li>No Fuss Distance Metric Learning using Proxies (ICCV 2017)</li>
<li>Deep Metric Learning with Angular Loss (ICCV 2017)</li>
<li>Sampling Matters in Deep Embedding Learning (ICCV 2017)</li>
<li>Deep Adversarial Metric Learning (CVPR 2018)</li>
<li>Classification is a Strong Baseline for Deep Metric Learning (BMVC 2019)</li>
<li>Hardness-Aware Deep Metric Learning (CVPR 2019)</li>
<li>Deep Asymmetric Metric Learning via Rich Relationship Mining (CVPR 2019)</li>
<li>Stochastic Class-based Hard Example Mining for Deep Metric Learning (CVPR 2019)</li>
<li>Ranked List Loss for Deep Metric Learning (CVPR 2019)</li>
<li>Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning (CVPR 2019)</li>
<li>Deep Metric Learning to Rank (CVPR 2019)</li>
<li>Divide and Conquer the Embedding Space for Metric Learning (CVPR 2019)</li>
<li>MIC: Mining Interclass Characteristics for Improved Metric Learning (ICCV 2019)</li>
<li>SoftTriple Loss: Deep Metric Learning Without Triplet Sampling (ICCV 2019)</li>
<li>Proxy Anchor Loss for Deep Metric Learning (CVPR 2020)</li>
</ul>
<h4 id="papers-categorized-by-the-optimizer-they-use">Papers categorized by the optimizer they use:<a class="headerlink" href="#papers-categorized-by-the-optimizer-they-use" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>SGD:</p>
<ul>
<li>Deep Spectral Clustering Learning (ICML 2017)</li>
<li>Deep Metric Learning with Angular Loss (ICCV 2017)</li>
<li>Hard-Aware Deeply Cascaded Embedding (ICCV 2017)</li>
<li>Deep Metric Learning with Hierarchical Triplet Loss (ECCV 2018)</li>
<li>Deep Asymmetric Metric Learning via Rich Relationship Mining (CVPR 2019)</li>
<li>Ranked List Loss for Deep Metric Learning (CVPR 2019)</li>
<li>Classification is a Strong Baseline for Deep Metric Learning (BMVC 2019)</li>
<li>Deep Metric Learning with Tuplet Margin Loss (ICCV 2019)</li>
</ul>
</li>
<li>
<p>RMSprop:</p>
<ul>
<li>Deep Metric Learning via Facility Location (CVPR 2017)</li>
<li>No Fuss Distance Metric Learning using Proxies (ICCV 2017)</li>
</ul>
</li>
<li>
<p>Adam:</p>
<ul>
<li>Improved Deep Metric Learning with Multi-class N-pair Loss Objective (Neurips 2016)</li>
<li>Sampling Matters in Deep Embedding Learning (ICCV 2017)</li>
<li>Hybrid-Attention based Decoupled Metric Learning for Zero-Shot Image Retrieval (CVPR 2019)</li>
<li>Stochastic Class-based Hard Example Mining for Deep Metric Learning (CVPR 2019)</li>
<li>Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning (CVPR 2019)</li>
<li>Deep Metric Learning to Rank (CVPR 2019)</li>
<li>Divide and Conquer the Embedding Space for Metric Learning (CVPR 2019)</li>
<li>SoftTriple Loss: Deep Metric Learning Without Triplet Sampling (ICCV 2019)</li>
<li>Metric Learning With HORDE: High-Order Regularizer for Deep Embeddings (ICCV 2019)</li>
<li>MIC: Mining Interclass Characteristics for Improved Metric Learning (ICCV 2019)</li>
</ul>
</li>
<li>
<p>AdamW</p>
<ul>
<li>Proxy Anchor Loss for Deep Metric Learning (CVPR 2020)</li>
</ul>
</li>
</ul>
<h4 id="papers-that-do-not-use-confidence-intervals">Papers that do not use confidence intervals:<a class="headerlink" href="#papers-that-do-not-use-confidence-intervals" title="Permanent link">&para;</a></h4>
<ul>
<li>All of the previously mentioned papers</li>
</ul>
<h4 id="papers-that-do-not-use-a-validation-set">Papers that do not use a validation set:<a class="headerlink" href="#papers-that-do-not-use-a-validation-set" title="Permanent link">&para;</a></h4>
<ul>
<li>All of the previously mentioned papers</li>
</ul>
<h2 id="frequently-asked-questions">Frequently Asked Questions<a class="headerlink" href="#frequently-asked-questions" title="Permanent link">&para;</a></h2>
<h4 id="do-you-have-slides-that-accompany-the-paper">Do you have slides that accompany the paper?<a class="headerlink" href="#do-you-have-slides-that-accompany-the-paper" title="Permanent link">&para;</a></h4>
<p>Slides are <a href="https://docs.google.com/presentation/d/1KnLDFzMKLYlnMzMDc7wyKHVAh5dJ9z6Fs1qto4OqQFY/edit?usp=sharing" target="_blank">here</a>.</p>
<h4 id="isnt-it-unfair-to-fix-the-model-optimizer-learning-rate-and-embedding-size">Isn't it unfair to fix the model, optimizer, learning rate, and embedding size?<a class="headerlink" href="#isnt-it-unfair-to-fix-the-model-optimizer-learning-rate-and-embedding-size" title="Permanent link">&para;</a></h4>
<p>Our goal was to compare algorithms fairly. To accomplish this, we used the same network, optimizer, learning rate, image transforms, and embedding dimensionality for each algorithm. There is no theoretical reason why changing any of these parameters would benefit one particular algorithm over the rest. If there is no theoretical reason, then we can only speculate, and if we add hyperparameters based on speculation, then the search space becomes too large to explore.</p>
<h4 id="why-was-the-batch-size-set-to-32-for-most-of-the-results">Why was the batch size set to 32 for most of the results?<a class="headerlink" href="#why-was-the-batch-size-set-to-32-for-most-of-the-results" title="Permanent link">&para;</a></h4>
<p>This was done for the sake of computational efficiency. Note that there are: </p>
<ul>
<li>3 datasets </li>
<li>14 algorithms </li>
<li>50 steps of bayesian optmization </li>
<li>4 fold cross validation </li>
</ul>
<p>This comes to 8400 models to train, which can take a considerable amount of time. Thus, a batch size of 32 made sense. It's also important to remember that there are real-world cases where a large batch size cannot be used. For example, if you want to train on large images, rather than the contrived case of 227x227, then training with a batch size of 32 suddenly makes a lot more sense because you are constrained by GPU memory. So it's reasonable to check the performance of these losses on a batch size of 32. </p>
<p>That said, there is a good theoretical reason for a larger batch size benefiting embedding losses more than classification losses. Specifically, embedding losses can benefit from the increased number of pairs/triplets in larger batches. To address this, we benchmarked the 14 methods on CUB200, using a batch size of 256. The results can be found in the supplementary section (the final page) of the paper.</p>
<h4 id="why-werent-more-hard-mining-methods-evaluated">Why weren't more hard-mining methods evaluated?<a class="headerlink" href="#why-werent-more-hard-mining-methods-evaluated" title="Permanent link">&para;</a></h4>
<p>We did test one loss+miner combination (Multi-similarity loss + their mining method). But we mainly wanted to do a thorough evaluation of loss functions, because that is the subject of most recent metric learning papers.   </p>
<h4 id="for-the-contrastive-loss-why-is-the-optimal-positive-margin-a-negative-value">For the contrastive loss, why is the optimal positive margin a negative value?<a class="headerlink" href="#for-the-contrastive-loss-why-is-the-optimal-positive-margin-a-negative-value" title="Permanent link">&para;</a></h4>
<p>A negative value should be equivalent to a margin of 0, because the distance between positive pairs cannot be negative, and the margin does not contribute to the gradient. So allowing the hyperparameter optimization to explore negative margins was unnecesary, but by the time I realized this, it wasn't worth changing the optimization bounds.</p>
<h2 id="reproducing-results">Reproducing results<a class="headerlink" href="#reproducing-results" title="Permanent link">&para;</a></h2>
<h3 id="download-the-experiment-folder">Download the experiment folder<a class="headerlink" href="#download-the-experiment-folder" title="Permanent link">&para;</a></h3>
<ol>
<li>Download <a href="../..#getting-started">run.py and set the default flags</a></li>
<li>Go to the <a href="https://docs.google.com/spreadsheets/d/1brUBishNxmld-KLDAJewIc43A4EVZk3gY6yKe8OIKbY/">benchmark spreadsheet</a></li>
<li>Find the experiment you want to reproduce, and click on the link in the "Config files" column.</li>
<li>You'll see 3 folders: one for CUB, one for Cars, and one for SOP. Open the folder for the dataset you want to train on.</li>
<li>Now you'll see several files and folders, one of which ends in "reproduction0". Download this folder. (It will include saved models. If you don't want to download the saved models, go into the folder and download just the "configs" folder.)</li>
</ol>
<h3 id="command-line-scripts">Command line scripts<a class="headerlink" href="#command-line-scripts" title="Permanent link">&para;</a></h3>
<p>Normally reproducing results is as easy as downloading an experiment folder, and <a href="../..#reproduce-an-experiment">using the <code>reproduce_results</code> flag</a>. However, there have been significant changes to the API since these experiments were run, so there are a couple of extra steps required, and they depend on the dataset. </p>
<p>Additionally, if you are reproducing an experiment for the <strong>Contrastive, Triplet, or SNR Contrastive losses</strong>, you have to delete the key/value pair called <code>avg_non_zero_only</code> in the <code>config_loss_and_miners.yaml</code> file. And for the <strong>Contrastive loss</strong>, you should delete the <code>use_similarity</code> key/value pair in <code>config_loss_and_miners.yaml</code>. </p>
<p>In the following code, <code>&lt;experiment_to_reproduce&gt;</code> refers to the folder that <strong>contains</strong> the <code>configs</code> folder.</p>
<ul>
<li>CUB200:</li>
</ul>
<div class="codehilite"><pre><span></span>python run.py --reproduce_results &lt;experiment_to_reproduce&gt; <span class="se">\</span>
--experiment_name &lt;your_experiment_name&gt; <span class="se">\</span>
--split_manager~SWAP~1 <span class="o">{</span>MLRCSplitManager: <span class="o">{}}</span> <span class="se">\</span>
--merge_argparse_when_resuming
</pre></div>


<ul>
<li>Cars196:</li>
</ul>
<div class="codehilite"><pre><span></span>python run.py --reproduce_results &lt;experiment_to_reproduce&gt; <span class="se">\</span>
--experiment_name &lt;your_experiment_name&gt; <span class="se">\</span>
--config_dataset <span class="o">[</span>default, with_cars196<span class="o">]</span> <span class="se">\</span>
--config_general <span class="o">[</span>default, with_cars196<span class="o">]</span> <span class="se">\</span>
--split_manager~SWAP~1 <span class="o">{</span>MLRCSplitManager: <span class="o">{}}</span> <span class="se">\</span>
--merge_argparse_when_resuming
</pre></div>


<ul>
<li>Stanford Online Products</li>
</ul>
<div class="codehilite"><pre><span></span>python run.py --reproduce_results &lt;experiment_to_reproduce&gt; <span class="se">\</span>
--experiment_name &lt;your_experiment_name&gt; <span class="se">\</span>
--config_dataset <span class="o">[</span>default, with_sop<span class="o">]</span> <span class="se">\</span>
--config_general <span class="o">[</span>default, with_sop<span class="o">]</span> <span class="se">\</span>
--split_manager~SWAP~1 <span class="o">{</span>MLRCSplitManager: <span class="o">{}}</span> <span class="se">\</span>
--merge_argparse_when_resuming
</pre></div>


<ul>
<li>CUB200 with batch size 256:</li>
</ul>
<div class="codehilite"><pre><span></span>python run.py --reproduce_results &lt;experiment_to_reproduce&gt; <span class="se">\</span>
--experiment_name &lt;your_experiment_name&gt; <span class="se">\</span>
--config_general <span class="o">[</span>default, with_256_batch<span class="o">]</span> <span class="se">\</span>
--split_manager~SWAP~1 <span class="o">{</span>MLRCSplitManager: <span class="o">{}}</span> <span class="se">\</span>
--merge_argparse_when_resuming
</pre></div>


<p>If you don't have the datasets and would like to download them into your <code>dataset_root</code> folder, you can add this flag to the CUB commands:</p>
<div class="codehilite"><pre><span></span>--dataset~OVERRIDE~ <span class="o">{</span>CUB200: <span class="o">{</span>download: True<span class="o">}}</span>
</pre></div>


<p>Likewise, for the Cars196 and Stanford Online Products commands, replace the <code>--config_dataset</code> flag with:</p>
<div class="codehilite"><pre><span></span>--dataset~OVERRIDE~ <span class="o">{</span>Cars196: <span class="o">{</span>download: True<span class="o">}}</span>
</pre></div>


<p>or </p>
<div class="codehilite"><pre><span></span>--dataset~OVERRIDE~ <span class="o">{</span>StanfordOnlineProducts: <span class="o">{</span>download: True<span class="o">}}</span>
</pre></div>


<h3 id="run-evaluation-on-the-test-set">Run evaluation on the test set<a class="headerlink" href="#run-evaluation-on-the-test-set" title="Permanent link">&para;</a></h3>
<p>After training is done, you can get the "separate 128-dim" test set performance:</p>
<div class="codehilite"><pre><span></span>python run.py --experiment_name &lt;your_experiment_name&gt; <span class="se">\</span>
--evaluate --splits_to_eval <span class="o">[</span>test<span class="o">]</span>
</pre></div>


<p>and the "concatenated 512-dim" test set performance:</p>
<div class="codehilite"><pre><span></span>python run.py --experiment_name &lt;your_experiment_name&gt; <span class="se">\</span>
--evaluate_ensemble --splits_to_eval <span class="o">[</span>test<span class="o">]</span>
</pre></div>


<p>Once evaluation is done, you can go to the <code>meta_logs</code> folder and view the results.</p>
                
                  
                
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../../code/utils/" title="Utils" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Utils
              </span>
            </div>
          </a>
        
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application.808e90bb.js"></script>
      
      <script>app.initialize({version:"1.1.dev0",url:{base:"../.."}})</script>
      
    
  </body>
</html>